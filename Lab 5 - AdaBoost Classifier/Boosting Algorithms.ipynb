{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Information\n",
    "\n",
    "Please enter the names and IDs of the two students below:\n",
    "\n",
    "1. **Name**: [Enter Student 1 Name Here]  \n",
    "   **ID**: `9XXXXXX` \n",
    "\n",
    "2. **Name**: [Enter Student 2 Name Here]  \n",
    "   **ID**: `9XXXXXX` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students Instructions\n",
    "\n",
    "Welcome to this learning module! As you embark on this journey, please keep the following in mind:\n",
    "\n",
    "- Clearly state your personal information where indicated.\n",
    "- Read the requirment carefully and refer to your lecture to understand any unclear concepts.\n",
    "- Hints are provided to guide you in one of the right direction but all ways lead to Rome.\n",
    "- **Keep the answers of the Essay questions in code cells for more clarity.**\n",
    "\n",
    "Remember, adhering to these guidelines is crucial for your success and will help you maximize your learning experience.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers Boosting Algorithms\n",
    "\n",
    "In this lab, we will implement the AdaBoost algorithm as an ensemble learning technique which\n",
    "aims to combine a number of weak classifiers to yield a strong classifier at the end.\n",
    "The idea of this lab is to identify whether a tumor with given characteristics is malignant or\n",
    "benign. This is a two-class classification problem.\n",
    "\n",
    "**HINT**: There are other boosting algorithms worth exploring like the xgboost.\n",
    "\n",
    "## Dataset and Features\n",
    "\n",
    "You will be working on the dataset from *Hastie et al,* for breast tumor classification with 10 features representing the tumor's:\n",
    "\n",
    "                              1. Area            6. Texture\n",
    "                              2. Perimeter       7. Symmetry\n",
    "                              3. Radius          8. Greyscale Level\n",
    "                              4. Compactness     9. Fractal Dimension\n",
    "                              5. Concavity      10. Coastline Approximation.\n",
    "There is one output variable which is diagnosis. It takes one of two values `+1` for malignant and `-1` for benign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Why it is sometimes better to have the two class values `+1` and `-1` instead of `+1`\n",
    "and `0`?\\\n",
    "**HINT :** Think about the voting scheme at the end of the boosting algorithm. How can the class values\n",
    "affect this scheme?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Your answer: \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Your answer: \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement\n",
    "You are required to fill the function `adaboost_classifier(Y_train, X_train, Y_test, X_test, T, clf).`\\\n",
    "This function takes as parameters:\n",
    "\n",
    "| | |\n",
    "|:---|:-|\n",
    "| **Y_train**| The target values for the training set |\n",
    "| **X_train**| The input features for the training set.|\n",
    "| **Y_test**| The target values for the test set.|\n",
    "| **Y_train**| The input features for the training set.|\n",
    "| **T**| The number of iterations of the AdaBoost Algorithm.|\n",
    "| **clf**| The classifier to be used. (In our case, we are using a decision tree stump as a base classifier). You can use any other classifier.|\n",
    "\n",
    "This function should return two values:\n",
    "- The accuracy of the model on the training set.\n",
    "- The accuracy of the model on the test set.\n",
    "\n",
    "\n",
    "#### Fair Note:\n",
    "In the explanation video, we assumed that (T) is the number of models you want to fit. However, this is not always the case. You may have a model base (like here we have decision trees) and you are allowed to use as many of it as you can. So (T) here becomes the number of iterations where your goal is to enhance the performance with as few iterations as possible. \n",
    "\n",
    "Do not get confused:\n",
    "- If your case is you have T models only, we set T = number of models to fit.\n",
    "- If you are allowed to use as many models as you can (as many decision trees as you need), then T is the number of iterations to choose. In such case, T becomes a parameter controlled by the programmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports ##\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** we prepared some utility functions to help you throughout the lab. please go and check the file *utils.py* and make sure you understand each function and know how to use it.\n",
    "\n",
    "### AdaBoost Implementation\n",
    "\n",
    "AdaBoost is an iterative algorithm that gives weights for the best classifier every iteration, updates weights of the data points, then repeats until convergence.\n",
    "\n",
    "The steps of the algorithm are:\n",
    "\n",
    "1. Initialize weights of the training examples:\n",
    "\n",
    "$$w_{m} = \\frac {1}{M}, m = 1,2,...M$$\n",
    "\n",
    "                                        M: number of training examples. \n",
    "\n",
    "2. For t=1 to $T$:\n",
    "\n",
    "    a) Select a classifier $h_{t}$ that best fits to the training data using weights $w_{m}$ of the training examples.\n",
    "\n",
    "    b) Compute error of $h_{t}$ as:\n",
    "$$err_{t} = \\frac {\\Sigma_{m=1}^{M} w_{m} \\phi (c_{m} \\neq h_{t}(x_{m}))}{\\Sigma_{m=1}^{M} w_{m}}$$\n",
    "\n",
    "    c) Compute weight of classifier:\n",
    "$$\\alpha_{t} = \\log (\\frac {1-err_{t}}{err_{t}} )$$\n",
    "\n",
    "    d) Update weights of wrongly classified examples:\n",
    "$$w_{m} = w_{m} * \\exp^{\\alpha_{t} \\phi (c_{m} \\neq h_{t}(x_{m}))}, \\space m = 1 ... M$$\n",
    "\n",
    "    e) Renormalize weights $w_{m}$\n",
    "\n",
    "\n",
    "\\\n",
    "3. Output: $C(x)= argmax_{k}\\space (\\space \\Sigma_{t=1}^{T} \\alpha_{t} * \\phi (h_{t}(x) = k)) \\space)$\n",
    "\n",
    "**Where** in step 2.B and 2.D, the $\\phi (y)$ function is called the *miss indicator* function that gives values:\n",
    "\n",
    "                                     1: if y is True\n",
    "                                     0: if y is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_classifier(Y_train, X_train, Y_test, X_test, T, clf):\n",
    "    \n",
    "    #TODO: FILL THE FUNCTION with the implementation as the steps above\n",
    "\n",
    "    # TODO [1]: Initialize weights\n",
    "    w=len(X_train)\n",
    "   \n",
    "    \n",
    "\n",
    "    ## TODO [2]:  Initialize the training and test data with empty array placeholders\n",
    "    #### Hint: what should be their shape?\n",
    "    pred_train = np.empty(len(X_train)) ## predicted classes of the training examples\n",
    "    pred_test = np.empty(len(X_test)) ## predicted classes of the test examples\n",
    "\n",
    "    ## TODO [3]: loop over the boosting iterations \n",
    "    for i in range(T): \n",
    "\n",
    "        # TODO [4]: Fit a classifier with the specific weights \n",
    "        ## TODO [4.A]: fit the classifier on the training data\n",
    "        clf.fit(X_train, Y_train, sample_weight=w)\n",
    "        #### Hint: search how sklearn.tree.DecisionTreeClassifier fits classifier on data\n",
    "        ### Hint: search for parameter weights in the fit matrix\n",
    "        \n",
    "        # TODO [4.B]: predict classes for the training data and test data\n",
    "        pred_train_i = clf.predict(X_train)\n",
    "        pred_test_i = clf.predict(X_test)\n",
    "        \n",
    "        # TODO [5]: calculate the miss Indicator function\n",
    "        I_train=Y_train!=pred_train_i\n",
    "        miss_Indicator=sum(I_train)\n",
    "        I_test=Y_train!=pred_test_i\n",
    "        miss_Indicator=sum(I_test)\n",
    "        # TODO [6]: calculate the error for the current classifier (err_t)\n",
    "        err_t = sum(w*I_train)/sum(w)\n",
    "        \n",
    "        # TODO [7]: calculate current classifier weight (Alpha_t)\n",
    "        alpha_t = 0.5 * np.log((1 - err_t) / err_t)\n",
    "        \n",
    "        # TODO [8]: update the weights \n",
    "        \n",
    "        # TODO [9] Add to the overall predictions\n",
    "\n",
    "        \n",
    "    # TODO [10]: Return error rate in train and test set\n",
    "    #### Hint: use function get_accuracy from utils.py\n",
    "    train_error = None\n",
    "    test_error = None\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Boosted Classifier\n",
    "\n",
    "Now we will use the function you implemented to build a classifer.\\\n",
    "You will not change code here, only read the code below and run it to see how **AdaBoost** enhanced the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data ...\n",
      "Number of Iterations :  10\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "Number of Iterations :  60\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "Number of Iterations :  110\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "Number of Iterations :  160\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "Number of Iterations :  210\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "Number of Iterations :  260\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "Number of Iterations :  310\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "Number of Iterations :  360\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n",
      "4380\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     acc_test\u001b[38;5;241m.\u001b[39mappend(acc_i[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Compare error rate vs number of iterations\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macc_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Fatma\\2ndTerm_3rdYear\\NN\\Labs\\Lab 5 - AdaBoost Classifier\\utils.py:17\u001b[0m, in \u001b[0;36mplot_accuracy\u001b[1;34m(acc_train, acc_test)\u001b[0m\n\u001b[0;32m     15\u001b[0m df_error \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([acc_train, acc_test])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     16\u001b[0m df_error\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m plot1 \u001b[38;5;241m=\u001b[39m \u001b[43mdf_error\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlightblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdarkblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m plot1\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of iterations\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m     20\u001b[0m plot1\u001b[38;5;241m.\u001b[39mset_xticklabels(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m450\u001b[39m, \u001b[38;5;241m50\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\plotting\\_core.py:975\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    972\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    973\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[1;32m--> 975\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(data, kind, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[0;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 71\u001b[0m \u001b[43mplot_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:446\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_adjust()\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_plot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_subplots()\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_plot()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:632\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_empty:\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno numeric data to plot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m numeric_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[1;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    }
   ],
   "source": [
    "#### DO NOT CHANGE CODE ####\n",
    "\n",
    "## First, read the dataset\n",
    "x,y = make_hastie_10_2()\n",
    "df = pd.DataFrame(x)\n",
    "df['Y'] = y\n",
    "print('Reading Data ...')\n",
    "\n",
    "# Split into training and test set\n",
    "train, test = train_test_split(df, test_size=0.2) # this function shuffles the data points, and splits the data into\n",
    "                                                  # 80% training set and 20% test set (indicated by test_size=0.2)\n",
    "\n",
    "\n",
    "X_train, Y_train = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "X_test, Y_test = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "# Fit a simple decision tree first\n",
    "\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "\n",
    "# Fit Adaboost classifier using a decision tree as base estimator\n",
    "# Test with different number of iterations\n",
    "acc_train, acc_test = [],[]\n",
    "x_range = range(10, 410, 50)\n",
    "for i in x_range:\n",
    "    print('Number of Iterations : ' , i)\n",
    "    acc_i = adaboost_classifier(Y_train, X_train, Y_test, X_test, i, clf_tree)\n",
    "    acc_train.append(acc_i[0])\n",
    "    acc_test.append(acc_i[1])\n",
    "\n",
    "# Compare error rate vs number of iterations\n",
    "utils.plot_accuracy(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Justify why the plot is the way it is (is it increasing or decreasing? why? when does it flattens out?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Your answer:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "The number of iterations (T) is what we call a hyper parameter:\n",
    "   - Its value differs from model to model and from problem to problem.\n",
    "   - Its value is not learnt by time, it is set by the programmer.\n",
    "   \n",
    "Suggest ways to select the optimal T keeping in mind that:\n",
    "   - If T is too big, the training time is large (you loop for T times, each time takes a model to fit and this model might take hours to fit)\n",
    "   - If T is too small, the boosting might not reach the best values it can get.\n",
    "   \n",
    "   \n",
    "\n",
    "**HINT**: Look at the graph of number of iterations vs performance and search for elbow method. Try to understand it and explain what it does.\\\n",
    "**HINT**: There are other hyper-parameter selection techniques, search for them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Your answer:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To ensure a smooth evaluation process, please follow these steps for submitting your work:\n",
    "\n",
    "1. **Prepare Your Submission:** Alongside your main notebook, include any additional files that are necessary for running the notebook successfully. This might include data files, images, or supplementary scripts.\n",
    "\n",
    "2. **Rename Your Files:** Before submission, please rename your notebook to reflect the IDs of the two students working on this project. The format should be `ID1_ID2`, where `ID1` and `ID2` are the student IDs. For example, if the student IDs are `9123456` and `9876543`, then your notebook should be named `9123456_9876543.ipynb`.\n",
    "\n",
    "3. **Check for Completeness:** Ensure that all required tasks are completed and that the notebook runs from start to finish without errors. This step is crucial for a smooth evaluation.\n",
    "\n",
    "4. **Submit Your Work:** Once everything is in order, submit your notebook and any additional files via the designated submission link on Google Classroom. Make sure you meet the submission deadline to avoid any late penalties.\n",
    "\n",
    "By following these instructions carefully, you help us in evaluating your work efficiently and fairly. If you encounter any difficulties or have questions about the submission process, please reach out as soon as possible.\n",
    "\n",
    "We look forward to seeing your completed projects and wish you the best of luck!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
